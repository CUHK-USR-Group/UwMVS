<h1>Learnable Cost Metric Based Multi-View Stereo for Point Cloud Reconstruction</h1>
<p><strong>Authors:</strong> \vskip 1em 	 	Guidong Yang$^\ast$, Xunkuai Zhou, Chuanxiang Gao, Xi Chen, and Ben M. Chen, \emph{Fellow, IEEE</p>
<h2>Abstract</h2>
<p>3D reconstruction is essential to defect localization. This paper proposes LCM-MVSNet, a novel multi-view stereo (MVS) network with learnable cost metric (LCM) for more accurate and complete dense point cloud reconstruction. To adapt to the scene variation and improve the reconstruction quality in non-Lambertian low-textured scenes, we propose LCM to adaptively aggregate multi-view matching similarity into the 3D cost volume by leveraging sparse point hints. The proposed LCM benefits the MVS approaches in four folds, including depth estimation enhancement, reconstruction quality improvement, memory footprint reduction, and computational burden alleviation, allowing the depth inference for high-resolution images to achieve more accurate and complete reconstruction. Additionally, we improve the depth estimation by enhancing the shallow feature propagation via a bottom-up pathway and strengthen the end-to-end supervision by adapting the focal loss to reduce ambiguity caused by sample imbalance. Extensive experiments are carefully conducted on three benchmark datasets to validate that our method achieves state-of-the-art performance on the \textit{DTU} and \textit{BlendedMVS} dataset, and exhibits strong generalization ability with a competitive performance on the \textit{Tanks and Temples} benchmark. Furthermore, we deploy our LCM-MVSNet into our UAV-based infrastructure defect inspection system for reconstruction-based defect localization, demonstrating the effectiveness, efficiency, and scalability of our method. More experiment results can be found in the Appendix~\footnote{shorturl.at/xFRSU}.</p>